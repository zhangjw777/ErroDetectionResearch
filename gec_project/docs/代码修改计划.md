# 代码修改计划：三大模块新增实现

## 背景
基于圆桌会议讨论结果，为增强论文创新性，需要在现有模型架构上新增三个模块：
1. **模块一**：句法-语义融合交互层 (Syntactic-Semantic Interaction Layer)
2. **模块二**：基于不确定性的动态损失加权 (Uncertainty-Weighted Loss)
3. **模块三**：错误感知多实例句级分类头 (Error-Aware Multi-Instance Head)

---

## 实施状态总结

### ✅ 已完成的任务

#### 步骤1：修改 modeling.py
- [x] 新增 `SyntaxSemanticInteractionLayer` 类
  - 实现门控融合公式：G = σ(W_g · [H_shared ; H_SVO] + b_g)
  - 支持可选的 LayerNorm
- [x] 新增 `ErrorAwareSentenceHead` 类
  - 实现错误置信度计算：e = 1 - P(KEEP)
  - 实现错误驱动注意力池化
  - 返回注意力权重用于可视化
  - **[Bug修复]** 支持 `label_mask` 参数，排除 CLS/子词位置
  - **[Bug修复]** 支持 `detach_confidence` 开关，控制是否截断梯度
- [x] 修改 `GECModelWithMTL.__init__`
  - 添加 SVO 中间表示生成层
  - 集成句法-语义融合层
  - 集成错误感知句级分类头
  - 支持配置开关控制各模块启用/禁用
- [x] 修改 `GECModelWithMTL.forward`
  - 实现完整的数据流：H_shared -> H_SVO -> 融合 -> GEC -> 句级检测
  - 支持返回注意力权重
  - **[Bug修复]** SVO Head 使用 H_SVO 而非 H_shared 进行预测
- [x] 更新 `create_model` 函数支持新参数

#### 步骤2：修改 loss.py
- [x] 新增 `UncertaintyWeightedLoss` 类
  - 实现公式：L_total = 1/2·exp(-s₁)·L_GEC + 1/2·exp(-s₂)·L_SVO + 1/2·exp(-s₃)·L_Sent + 1/2·(s₁+s₂+s₃)
  - 使用对数方差 s_i = log(σ_i²) 保证数值稳定性
  - 提供 get_task_weights() 和 get_uncertainties() 分析方法
  - 返回完整的损失字典（包含 sigma、weighted loss 等）
- [x] 新增 `MultiTaskLossWithUncertainty` 类
  - 整合 Focal Loss、CrossEntropy 和不确定性加权
  - 支持固定权重和不确定性加权两种模式切换

#### 步骤3：修改 trainer.py
- [x] 集成不确定性加权损失
- [x] 修改优化器配置，支持不确定性参数使用较大学习率
- [x] 添加训练日志记录（TensorBoard 记录不确定性参数）
  - **[增强]** 添加 sigma (σ) 标准差的 TensorBoard 记录
  - **[增强]** 添加 weighted_loss 加权损失的 TensorBoard 记录
- [x] 保存不确定性参数历史用于分析
- [x] 支持两种损失函数接口的兼容

#### 步骤4：修改 config.py
- [x] 添加模块一配置项：USE_SYNTAX_SEMANTIC_FUSION, SYNTAX_FUSION_USE_LAYER_NORM
- [x] 添加模块二配置项：USE_UNCERTAINTY_WEIGHTING, UNCERTAINTY_INIT_LOG_VAR, UNCERTAINTY_LR_MULTIPLIER
- [x] 添加模块三配置项：USE_ERROR_AWARE_SENT_HEAD, KEEP_LABEL_IDX, DETACH_ERROR_CONFIDENCE

#### 步骤5：测试与验证
- [x] 单元测试：验证各模块前向传播 (test_modules.py 通过)
- [ ] 集成测试：验证完整训练流程
- [ ] 梯度检查：确保梯度正常流动

---

## Bug 修复记录 (2024-01)

### Issue 1: SVO Head 没有被 SVO 任务直接监督
**问题**：原实现中 SVO Head 使用 `H_shared` 而非 `H_SVO` 进行预测，导致 SVO 任务的梯度没有流向 `svo_hidden_proj` 层。

**修复**：
```python
# Before
svo_logits = self.svo_classifier(h_shared)

# After  
svo_logits = self.svo_classifier(h_svo)
```

**文件**：`src/modeling.py` - `GECModelWithMTL.forward()`

---

### Issue 2: 任务权重的 TensorBoard 可视化不完整
**问题**：原实现只记录了 `log_var` 和 `weight`，缺少 `sigma` (σ) 和加权后损失的记录。

**修复**：在 `trainer.py` 中增强 TensorBoard 记录：
```python
# 新增记录项
self.writer.add_scalar('uncertainty/sigma_gec', loss_dict['sigma_gec'], self.global_step)
self.writer.add_scalar('uncertainty/sigma_svo', loss_dict['sigma_svo'], self.global_step)
self.writer.add_scalar('uncertainty/sigma_sent', loss_dict['sigma_sent'], self.global_step)
self.writer.add_scalar('uncertainty/weighted_gec', loss_dict['weighted_gec'], self.global_step)
self.writer.add_scalar('uncertainty/weighted_svo', loss_dict['weighted_svo'], self.global_step)
self.writer.add_scalar('uncertainty/weighted_sent', loss_dict['weighted_sent'], self.global_step)
```

**文件**：`src/trainer.py` - 训练循环中的 TensorBoard 记录部分

---

### Issue 3: ErrorAwareSentenceHead 没有使用 label_mask
**问题**：CLS 和子词位置也参与了错误注意力计算，应该被排除。

**修复**：
```python
# 合并 attention_mask 和 label_mask
if label_mask is not None:
    combined_mask = attention_mask * label_mask
else:
    combined_mask = attention_mask

# 使用合并后的 mask
error_confidence = error_confidence.masked_fill(combined_mask == 0, float('-inf'))
```

**文件**：`src/modeling.py` - `ErrorAwareSentenceHead.forward()`

---

### Issue 4: DETACH_ERROR_CONFIDENCE 开关未实际使用
**问题**：配置项定义了但代码中没有使用。

**修复**：
```python
def __init__(self, hidden_size: int, num_classes: int = 2, detach_confidence: bool = False):
    self.detach_confidence = detach_confidence

def forward(...):
    error_confidence = 1 - p_keep
    if self.detach_confidence:
        error_confidence = error_confidence.detach()  # 截断梯度
```

**文件**：`src/modeling.py` - `ErrorAwareSentenceHead` 类

---

### Issue 5: UncertaintyWeightedLoss 设备不匹配 (RuntimeError)
**问题**：`criterion` 模块创建后没有移动到 GPU，导致 `log_var_*` 参数在 CPU 上，而输入损失在 GPU 上。

**错误信息**：
```
RuntimeError: Expected all tensors to be on the same device, 
but found at least two devices, cuda:0 and cpu!
```

**修复**：
```python
# Before
criterion = MultiTaskLossWithUncertainty(...)

# After
criterion = MultiTaskLossWithUncertainty(...).to(device)
```

**文件**：`src/trainer.py` - `main()` 函数中的损失函数初始化部分

---

## Bug 修复记录 (2024-11-30) - DDP 分布式训练问题

### Issue 6: BERT Pooler 层导致 DDP 报错
**问题**：当 `USE_ERROR_AWARE_SENT_HEAD = True` 时，使用自定义的 `ErrorAwareSentenceHead`（基于 token 的注意力池化），完全没有使用 `bert.pooler` 输出的 `pooler_output`。因此 Pooler 层的参数在前向传播中被闲置，导致 DDP 报错。

**错误信息**：
```
RuntimeError: Expected to have finished reduction in the prior iteration...
Parameter indices which did not receive grad: 197 198
(bert.pooler.dense.weight 和 bert.pooler.dense.bias)
```

**修复**：在 `BertModel` 初始化时根据是否使用 `ErrorAwareSentenceHead` 决定是否添加 pooling 层：
```python
# Before
self.bert = BertModel(config)

# After
# 当使用 ErrorAwareSentenceHead 时，不需要 BERT 的 pooler 层
# 如果不禁用，pooler 的参数不会参与梯度计算，导致 DDP 报错
self.bert = BertModel(config, add_pooling_layer=not use_error_aware_sent_head)
```

**文件**：`src/modeling.py` - `GECModelWithMTL.__init__()`

---

### Issue 7: evaluate 函数缺少 label_mask 参数
**问题**：在 `trainer.py` 的 `evaluate` 函数中，模型前向传播时忘记传入 `label_mask` 参数，导致 `ErrorAwareSentenceHead` 无法正确构建 `valid_mask`。

**修复**：
```python
# Before
gec_logits, svo_logits, sent_logits = self.model(
    input_ids=input_ids,
    attention_mask=attention_mask
)

# After
gec_logits, svo_logits, sent_logits = self.model(
    input_ids=input_ids,
    attention_mask=attention_mask,
    label_mask=label_mask  # 修复：传入 label_mask 用于 ErrorAwareSentenceHead
)
```

**文件**：`src/trainer.py` - `GECTrainer.evaluate()`

---

### Issue 8: criterion 不确定性参数在 DDP 模式下梯度不同步
**问题**：`MultiTaskLossWithUncertainty` 包含可学习参数 `log_var_gec` 等。在 DDP 模式下，`model` 被 `DDP()` 包装（会自动同步梯度），但 `criterion`（损失函数）没有被包装。后果是在双卡训练时，GPU-0 和 GPU-1 上的 `log_var` 参数会根据各自卡上的数据计算梯度并更新。由于没有梯度同步（AllReduce），两张卡学到的任务权重（σ）会逐渐发生偏离（Diverge）。

**修复**：添加手动梯度同步函数，在参数更新前对不确定性参数的梯度进行 AllReduce：
```python
def _sync_uncertainty_gradients(self):
    """
    在 DDP 模式下同步不确定性参数的梯度
    """
    if not self.use_ddp or not self.use_uncertainty_weighting:
        return
    
    uncertainty_params = self.criterion.get_uncertainty_params()
    if uncertainty_params is None:
        return
    
    for name, param in uncertainty_params.items():
        if param.grad is not None:
            # 对梯度进行 AllReduce (平均)
            dist.all_reduce(param.grad, op=dist.ReduceOp.SUM)
            param.grad /= get_world_size()
```

**调用位置**：在 `train_epoch` 的梯度累积步骤中，`scaler.step(optimizer)` 之前调用。

**文件**：`src/trainer.py` - 新增 `GECTrainer._sync_uncertainty_gradients()` 方法

---

### Issue 9: DETACH_ERROR_CONFIDENCE 和 SYNTAX_FUSION_USE_LAYER_NORM 配置未接入
**问题**：
1. `config.py` 定义了 `DETACH_ERROR_CONFIDENCE = False`，但 `trainer.py` 中创建模型时没有传入
2. `config.py` 定义了 `SYNTAX_FUSION_USE_LAYER_NORM = True`，但 `GECModelWithMTL` 写死了 `use_layer_norm=True`

**修复**：
1. 在 `GECModelWithMTL.__init__` 中增加 `syntax_fusion_use_layer_norm` 参数
2. 在 `create_model` 函数中增加 `syntax_fusion_use_layer_norm` 参数
3. 在 `trainer.py` 中从 config 读取这两个配置项并传入

```python
# trainer.py - main() 函数
detach_error_confidence = getattr(cfg, 'DETACH_ERROR_CONFIDENCE', False)
syntax_fusion_use_layer_norm = getattr(cfg, 'SYNTAX_FUSION_USE_LAYER_NORM', True)

model = create_model(
    ...
    detach_error_confidence=detach_error_confidence,
    syntax_fusion_use_layer_norm=syntax_fusion_use_layer_norm
)
```

**文件**：
- `src/modeling.py` - `GECModelWithMTL.__init__()` 和 `create_model()`
**文件**：`src/trainer.py` - `main()` 函数

---

## Bug 修复记录 (2024-12-04) - 推理代码问题修复

### Issue 10: predictor.py 中 label_mask 缺失
**问题**：在 `GEDPredictor.predict()` 方法中，调用模型时没有传入 `label_mask` 参数，导致 `ErrorAwareSentenceHead` 无法正确计算 `valid_mask`，只能退化为使用 `attention_mask`。这会导致 `[CLS]`、`[SEP]`、子词续接位置也参与句级错误注意力计算，造成预测不稳定。

**修复**：在 `predict()` 方法中构造 `label_mask` 并传入模型：
```python
# 构造 label_mask：标记哪些位置是真实字符的第一个子词
label_mask_list = [0]  # [CLS] 位置为 0
for token in tokens:
    token_ids = self.tokenizer.encode(token, add_special_tokens=False)
    if len(token_ids) > 0:
        label_mask_list.append(1)  # 真实字符的第一个子词
        label_mask_list.extend([0] * (len(token_ids) - 1))  # 子词续接标记为 0
label_mask_list.append(0)  # [SEP] 位置为 0

label_mask = torch.tensor([label_mask_list], dtype=torch.long).to(self.device)

# 模型预测 - 传入 label_mask
gec_logits, svo_logits, sent_logits = self.model(
    input_ids=input_ids_tensor,
    attention_mask=attention_mask,
    label_mask=label_mask  # 修复：传入 label_mask
)
```

**文件**：`src/predictor.py` - `GEDPredictor.predict()`

---

### Feature: 新增 GEDEvaluator 评估类
**描述**：新增 `GEDEvaluator` 类用于评估模型性能，支持字符级和句级两种评估模式。

**功能特性**：
1. **字符级评估** (`evaluate_char_level`)：
   - 计算模型在字符级别的错误检测能力
   - 指标：Precision、Recall、F1、F2、F0.5、TP、FP、FN

2. **句级评估** (`evaluate_sentence_level`)：
   - 计算模型在句子级别的错误检测能力
   - 指标：Precision、Recall、F1、F2、Accuracy、TP、FP、FN、TN

3. **综合评估** (`evaluate`)：
   - 同时计算字符级和句级指标

4. **数据格式兼容性**：
   - 字典格式：`{'source': [...], 'target': [...], 'type': [...]}`
   - 列表格式：`[{'source': str, 'target': str}, ...]`
   - 元组格式：`[(source, target), ...]`

**使用示例**：
```python
# 创建评估器
evaluator = GEDEvaluator(predictor)

# 准备数据 (用户提供的格式)
data = {
    'source': ['潜在投标人需及时査看邮件确认信息，', '无凭无据...'],
    'target': ['潜在投标人需及时查看邮件确认信息，', '无凭无据...'],
    'type': ['negative', 'negative']
}

# 综合评估
results = evaluator.evaluate(data, error_threshold=0.2)
evaluator.print_report(results)

# 或单独评估
char_results = evaluator.evaluate_char_level(data)
sent_results = evaluator.evaluate_sentence_level(data, error_threshold=0.2)
```

**文件**：`src/predictor.py` - 新增 `GEDEvaluator` 类

**说明**：为了减小 `predictor.py` 文件体积并便于编写评估主函数，`GEDEvaluator` 类已从 `src/predictor.py` 移动到新的文件 `src/evaluate.py`，并在 `evaluate.py` 中提供 `main()` 用于直接运行评估。

---

## 修改文件清单

### 1. `src/modeling.py` - 模型架构修改

#### 1.1 新增模块一：句法-语义融合交互层

**插入位置**：MacBERT输出之后，GEC Head之前

**新增类**：`SyntaxSemanticInteractionLayer`

```python
class SyntaxSemanticInteractionLayer(nn.Module):
    """
    句法-语义融合交互层
    
    将SVO辅助任务的句法表示与BERT的语义表示进行门控融合，
    实现显式句法先验注入到GEC表示中。
    
    公式：
    - G = σ(W_g · [H_shared ; H_SVO] + b_g)
    - T = W_t · H_SVO + b_t
    - H_GEC_input = H_shared + G ⊙ T
    """
    def __init__(self, hidden_size: int):
        super().__init__()
        # 门控投影：2d -> d
        self.gate_proj = nn.Linear(hidden_size * 2, hidden_size)
        # 语法变换：d -> d
        self.syntax_transform = nn.Linear(hidden_size, hidden_size)
        # 可选：融合后的LayerNorm
        self.layer_norm = nn.LayerNorm(hidden_size)
    
    def forward(self, h_shared: torch.Tensor, h_svo: torch.Tensor) -> torch.Tensor:
        """
        Args:
            h_shared: [B, L, d] - BERT编码器输出
            h_svo: [B, L, d] - SVO中间表示
        Returns:
            h_gec_input: [B, L, d] - 融合后的表示
        """
        # 拼接
        concat = torch.cat([h_shared, h_svo], dim=-1)  # [B, L, 2d]
        # 门控向量
        gate = torch.sigmoid(self.gate_proj(concat))  # [B, L, d]
        # 语法变换
        syntax_transformed = self.syntax_transform(h_svo)  # [B, L, d]
        # 门控融合
        h_gec_input = h_shared + gate * syntax_transformed
        # LayerNorm
        h_gec_input = self.layer_norm(h_gec_input)
        return h_gec_input
```

#### 1.2 新增SVO中间表示生成层

**目的**：从BERT输出生成SVO任务的中间表示 `H_SVO`

```python
# 在GECModelWithMTL.__init__中新增
self.svo_hidden_proj = nn.Linear(config.hidden_size, config.hidden_size)
```

#### 1.3 新增模块三：错误感知多实例句级分类头

**替换原有的**：`self.sent_error_classifier = nn.Linear(config.hidden_size, 2)`

**新增类**：`ErrorAwareSentenceHead`

```python
class ErrorAwareSentenceHead(nn.Module):
    """
    错误感知多实例句级分类头
    
    将句子视为token实例集合，使用GEC预测的错误置信度驱动的
    注意力池化构造句级表示，显式对齐token-level与sentence-level。
    
    公式：
    - e_i = 1 - P(label_i = KEEP)  # 错误置信度
    - α_i = softmax(e_i)           # 错误驱动注意力
    - V_sent = Σ α_i · H_i         # 错误感知池化
    - y_sent = MLP(V_sent)         # 句级预测
    """
    def __init__(self, hidden_size: int, num_classes: int = 2):
        super().__init__()
        self.classifier = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size // 2, num_classes)
        )
    
    def forward(
        self, 
        h_tokens: torch.Tensor,      # [B, L, d]
        gec_logits: torch.Tensor,    # [B, L, C]
        attention_mask: torch.Tensor, # [B, L]
        keep_label_idx: int = 0       # KEEP标签的索引
    ) -> torch.Tensor:
        """
        Args:
            h_tokens: token级表示 (融合后的H_GEC_input)
            gec_logits: GEC Head的输出logits
            attention_mask: padding mask
            keep_label_idx: KEEP标签在标签表中的索引
        Returns:
            sent_logits: [B, num_classes]
        """
        # 1. 计算错误置信度 e = 1 - P(KEEP)
        gec_probs = torch.softmax(gec_logits, dim=-1)  # [B, L, C]
        p_keep = gec_probs[:, :, keep_label_idx]       # [B, L]
        error_confidence = 1 - p_keep                   # [B, L]
        
        # 2. Mask padding位置
        error_confidence = error_confidence.masked_fill(
            attention_mask == 0, float('-inf')
        )
        
        # 3. 错误驱动注意力权重
        alpha = torch.softmax(error_confidence, dim=-1)  # [B, L]
        
        # 4. 错误感知池化
        alpha = alpha.unsqueeze(-1)  # [B, L, 1]
        v_sent = torch.sum(alpha * h_tokens, dim=1)  # [B, d]
        
        # 5. 句级分类
        sent_logits = self.classifier(v_sent)  # [B, num_classes]
        
        return sent_logits
```

#### 1.4 修改 `GECModelWithMTL` 类

**修改__init__方法**：
```python
def __init__(self, config, num_gec_labels: int, num_svo_labels: int):
    super().__init__(config)
    self.num_gec_labels = num_gec_labels
    self.num_svo_labels = num_svo_labels
    
    # BERT Encoder
    self.bert = BertModel(config)
    
    # Dropout
    self.dropout = nn.Dropout(config.hidden_dropout_prob)
    
    # ========== 新增：SVO中间表示生成层 ==========
    self.svo_hidden_proj = nn.Linear(config.hidden_size, config.hidden_size)
    
    # ========== 新增：句法-语义融合交互层 ==========
    self.syntax_semantic_interaction = SyntaxSemanticInteractionLayer(config.hidden_size)
    
    # GEC Head (主任务) - 使用融合后的表示
    self.gec_classifier = nn.Linear(config.hidden_size, num_gec_labels)
    
    # SVO Head (辅助任务1) - 使用BERT输出
    self.svo_classifier = nn.Linear(config.hidden_size, num_svo_labels)
    
    # ========== 修改：错误感知句级分类头 ==========
    # 原: self.sent_error_classifier = nn.Linear(config.hidden_size, 2)
    self.sent_error_head = ErrorAwareSentenceHead(config.hidden_size, num_classes=2)
    
    self.init_weights()
```

**修改forward方法**：
```python
def forward(
    self,
    input_ids: torch.Tensor,
    attention_mask: Optional[torch.Tensor] = None,
    token_type_ids: Optional[torch.Tensor] = None,
    gec_labels: Optional[torch.Tensor] = None,
    svo_labels: Optional[torch.Tensor] = None,
    sent_labels: Optional[torch.Tensor] = None,
    label_mask: Optional[torch.Tensor] = None,
) -> Tuple[torch.Tensor, ...]:
    
    # BERT编码
    outputs = self.bert(
        input_ids=input_ids,
        attention_mask=attention_mask,
        token_type_ids=token_type_ids
    )
    
    # 获取序列输出 [batch_size, seq_len, hidden_size]
    h_shared = outputs.last_hidden_state
    h_shared = self.dropout(h_shared)
    
    # ========== 新增：生成SVO中间表示 ==========
    h_svo = self.svo_hidden_proj(h_shared)
    h_svo = torch.relu(h_svo)
    
    # ========== 新增：句法-语义融合 ==========
    h_gec_input = self.syntax_semantic_interaction(h_shared, h_svo)
    
    # SVO Head (使用h_shared)
    svo_logits = self.svo_classifier(h_shared)  # [B, L, num_svo_labels]
    
    # GEC Head (使用融合后的h_gec_input)
    gec_logits = self.gec_classifier(h_gec_input)  # [B, L, num_gec_labels]
    
    # ========== 修改：错误感知句级分类头 ==========
    sent_logits = self.sent_error_head(
        h_tokens=h_gec_input,
        gec_logits=gec_logits,
        attention_mask=attention_mask,
        keep_label_idx=0  # 假设KEEP是第0个标签
    )  # [B, 2]
    
    return gec_logits, svo_logits, sent_logits
```

---

### 2. `src/loss.py` - 损失函数修改

#### 2.1 新增模块二：不确定性加权损失

**新增类**：`UncertaintyWeightedLoss`

```python
class UncertaintyWeightedLoss(nn.Module):
    """
    基于同方差不确定性的动态多任务损失加权
    
    基于 "Multi-Task Learning Using Uncertainty to Weigh Losses" (CVPR 2018)
    
    公式：
    L_total = 1/2·exp(-s₁)·L_GEC + 1/2·exp(-s₂)·L_SVO + 1/2·exp(-s₃)·L_Sent
              + 1/2·(s₁ + s₂ + s₃)
    
    其中 s_i = log(σ_i²) 为可学习的对数方差参数
    """
    def __init__(self):
        super().__init__()
        # 初始化对数方差参数（log_vars = log(σ²)），初始为0
        self.log_var_gec = nn.Parameter(torch.zeros(1))
        self.log_var_svo = nn.Parameter(torch.zeros(1))
        self.log_var_sent = nn.Parameter(torch.zeros(1))
    
    def forward(
        self, 
        loss_gec: torch.Tensor, 
        loss_svo: torch.Tensor, 
        loss_sent: torch.Tensor
    ) -> Tuple[torch.Tensor, dict]:
        """
        Args:
            loss_gec: GEC任务损失
            loss_svo: SVO任务损失
            loss_sent: 句级任务损失
        Returns:
            total_loss: 加权后的总损失
            loss_dict: 包含各项损失和不确定性参数的字典
        """
        # 计算加权损失
        precision_gec = torch.exp(-self.log_var_gec)
        precision_svo = torch.exp(-self.log_var_svo)
        precision_sent = torch.exp(-self.log_var_sent)
        
        weighted_gec = 0.5 * precision_gec * loss_gec
        weighted_svo = 0.5 * precision_svo * loss_svo
        weighted_sent = 0.5 * precision_sent * loss_sent
        
        # 正则项
        regularization = 0.5 * (self.log_var_gec + self.log_var_svo + self.log_var_sent)
        
        # 总损失
        total_loss = weighted_gec + weighted_svo + weighted_sent + regularization
        
        # 返回详细信息用于日志记录
        loss_dict = {
            'loss_total': total_loss.item(),
            'loss_gec': loss_gec.item(),
            'loss_svo': loss_svo.item(),
            'loss_sent': loss_sent.item(),
            'log_var_gec': self.log_var_gec.item(),
            'log_var_svo': self.log_var_svo.item(),
            'log_var_sent': self.log_var_sent.item(),
            'sigma_gec': torch.exp(0.5 * self.log_var_gec).item(),
            'sigma_svo': torch.exp(0.5 * self.log_var_svo).item(),
            'sigma_sent': torch.exp(0.5 * self.log_var_sent).item(),
        }
        
        return total_loss, loss_dict
```

---

### 3. `src/trainer.py` - 训练器修改

#### 3.1 集成不确定性加权损失

**修改点**：
1. 在训练器初始化时创建 `UncertaintyWeightedLoss` 实例
2. 修改训练循环，使用不确定性加权计算总损失
3. 添加不确定性参数到优化器
4. 记录不确定性参数的训练曲线

```python
# 在Trainer.__init__中新增
from src.loss import UncertaintyWeightedLoss
self.uncertainty_loss = UncertaintyWeightedLoss().to(device)

# 修改优化器，添加不确定性参数
self.optimizer = torch.optim.AdamW([
    {'params': self.model.parameters()},
    {'params': self.uncertainty_loss.parameters(), 'lr': 1e-3}  # 不确定性参数用较大学习率
], lr=self.config.learning_rate)
```

---

### 4. `src/config.py` - 配置修改

**新增配置项**：
```python
# 句法-语义融合层配置
use_syntax_semantic_fusion: bool = True

# 不确定性加权配置
use_uncertainty_weighting: bool = True

# 错误感知句级头配置
use_error_aware_sent_head: bool = True
keep_label_idx: int = 0  # KEEP标签索引

# 是否detach错误置信度梯度（用于消融实验）
detach_error_confidence: bool = False
```

---

## 实施步骤

### 步骤1：修改 modeling.py
- [x] 新增 `SyntaxSemanticInteractionLayer` 类
- [x] 新增 `ErrorAwareSentenceHead` 类
- [x] 修改 `GECModelWithMTL.__init__`
- [x] 修改 `GECModelWithMTL.forward`

### 步骤2：修改 loss.py
- [x] 新增 `UncertaintyWeightedLoss` 类
- [x] 新增 `MultiTaskLossWithUncertainty` 类

### 步骤3：修改 trainer.py
- [x] 集成不确定性加权损失
- [x] 修改优化器配置
- [x] 添加训练日志记录

### 步骤4：修改 config.py
- [x] 添加新模块的配置项

### 步骤5：测试与验证
- [ ] 单元测试：验证各模块前向传播
- [ ] 集成测试：验证完整训练流程
- [ ] 梯度检查：确保梯度正常流动

---

## 注意事项

1. **Padding处理**：在错误感知句级头中，务必用attention_mask遮住padding位置
2. **KEEP标签索引**：需要确认label_map.txt中KEEP标签的实际索引
3. **梯度流动**：默认不detach错误置信度，让句级loss能反向影响token表示
4. **数值稳定性**：不确定性参数使用log_var形式，避免σ为负或过小

---

## 论文贡献点对应

| 贡献点 | 对应模块 | 代码文件 |
|--------|----------|----------|
| 结构层面：句法引导的表示细化 | SyntaxSemanticInteractionLayer | modeling.py |
| 优化层面：自适应多任务平衡 | UncertaintyWeightedLoss | loss.py |
| 预测层面：错误感知句级分类 | ErrorAwareSentenceHead | modeling.py |

---

## 命名规范修正记录 (2024-12)

### GEC → GED 命名规范化

**背景**：项目实际是**语法错误检测（Grammatical Error Detection, GED）**任务，而非纠错（Correction），但代码中错误使用了 GEC 命名。需要进行批量重命名以保持术语一致性。

**例外**：`config.py` 中的 `GEC_KEEP_LABEL`、`GEC_DELETE_LABEL`、`GEC_APPEND_PREFIX`、`GEC_REPLACE_PREFIX` 保持不变，因为这些是实际的 GECToR 标签系统命名。

**修改清单**：

| 文件 | 修改类型 | 旧名称 → 新名称 |
|------|----------|-----------------|
| modeling.py | 类名 | GECModelWithMTL → GEDModelWithMTL |
| modeling.py | 类名 | GECModelConfig → GEDModelConfig |
| modeling.py | 变量名 | h_gec_input → h_ged_input |
| modeling.py | 变量名 | gec_logits → ged_logits |
| modeling.py | 变量名 | gec_classifier → ged_classifier |
| modeling.py | 函数参数 | num_gec_labels → num_ged_labels |
| loss.py | 变量名 | loss_gec → loss_ged |
| loss.py | 变量名 | log_var_gec → log_var_ged |
| loss.py | 变量名 | sigma_gec → sigma_ged |
| loss.py | 变量名 | weight_gec → weight_ged |
| loss.py | 变量名 | weighted_gec → weighted_ged |
| dataset.py | 类名 | GECDataset → GEDDataset |
| dataset.py | 变量名 | gec_label_map → ged_label_map |
| dataset.py | 变量名 | gec_labels → ged_labels |
| trainer.py | 类名 | GECTrainer → GEDTrainer |
| trainer.py | 变量名 | total_gec_loss → total_ged_loss |
| trainer.py | 变量名 | all_gec_preds → all_ged_preds |
| predictor.py | 类名 | GECPredictor → GEDPredictor |
| predictor.py | 变量名 | id2gec_label → id2ged_label |
| test_modules.py | 导入 | GECModelWithMTL → GEDModelWithMTL |
| test_modules.py | 变量名 | loss_gec → loss_ged, gec_logits → ged_logits 等 |
| export_onnx.py | 导入 | GECModelWithMTL → GEDModelWithMTL |
| export_onnx.py | 导入 | GECPredictor → GEDPredictor |
| export_onnx.py | 变量名 | gec_label_map → ged_label_map |
| export_onnx.py | ONNX输出 | gec_logits → ged_logits |

**注意**：JSON 数据文件中的 `gec_labels` 键名保持不变，`dataset.py` 中通过 `item.get("gec_labels", ...)` 读取。
