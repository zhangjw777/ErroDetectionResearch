# 代码修改计划：三大模块新增实现

## 背景
基于圆桌会议讨论结果，为增强论文创新性，需要在现有模型架构上新增三个模块：
1. **模块一**：句法-语义融合交互层 (Syntactic-Semantic Interaction Layer)
2. **模块二**：基于不确定性的动态损失加权 (Uncertainty-Weighted Loss)
3. **模块三**：错误感知多实例句级分类头 (Error-Aware Multi-Instance Head)

---

## 实施状态总结

### ✅ 已完成的任务

#### 步骤1：修改 modeling.py
- [x] 新增 `SyntaxSemanticInteractionLayer` 类
  - 实现门控融合公式：G = σ(W_g · [H_shared ; H_SVO] + b_g)
  - 支持可选的 LayerNorm
- [x] 新增 `ErrorAwareSentenceHead` 类
  - 实现错误置信度计算：e = 1 - P(KEEP)
  - 实现错误驱动注意力池化
  - 返回注意力权重用于可视化
- [x] 修改 `GECModelWithMTL.__init__`
  - 添加 SVO 中间表示生成层
  - 集成句法-语义融合层
  - 集成错误感知句级分类头
  - 支持配置开关控制各模块启用/禁用
- [x] 修改 `GECModelWithMTL.forward`
  - 实现完整的数据流：H_shared -> H_SVO -> 融合 -> GEC -> 句级检测
  - 支持返回注意力权重
- [x] 更新 `create_model` 函数支持新参数

#### 步骤2：修改 loss.py
- [x] 新增 `UncertaintyWeightedLoss` 类
  - 实现公式：L_total = 1/2·exp(-s₁)·L_GEC + 1/2·exp(-s₂)·L_SVO + 1/2·exp(-s₃)·L_Sent + 1/2·(s₁+s₂+s₃)
  - 使用对数方差 s_i = log(σ_i²) 保证数值稳定性
  - 提供 get_task_weights() 和 get_uncertainties() 分析方法
- [x] 新增 `MultiTaskLossWithUncertainty` 类
  - 整合 Focal Loss、CrossEntropy 和不确定性加权
  - 支持固定权重和不确定性加权两种模式切换

#### 步骤3：修改 trainer.py
- [x] 集成不确定性加权损失
- [x] 修改优化器配置，支持不确定性参数使用较大学习率
- [x] 添加训练日志记录（TensorBoard 记录不确定性参数）
- [x] 保存不确定性参数历史用于分析
- [x] 支持两种损失函数接口的兼容

#### 步骤4：修改 config.py
- [x] 添加模块一配置项：USE_SYNTAX_SEMANTIC_FUSION, SYNTAX_FUSION_USE_LAYER_NORM
- [x] 添加模块二配置项：USE_UNCERTAINTY_WEIGHTING, UNCERTAINTY_INIT_LOG_VAR, UNCERTAINTY_LR_MULTIPLIER
- [x] 添加模块三配置项：USE_ERROR_AWARE_SENT_HEAD, KEEP_LABEL_IDX, DETACH_ERROR_CONFIDENCE

---

## 修改文件清单

### 1. `src/modeling.py` - 模型架构修改

#### 1.1 新增模块一：句法-语义融合交互层

**插入位置**：MacBERT输出之后，GEC Head之前

**新增类**：`SyntaxSemanticInteractionLayer`

```python
class SyntaxSemanticInteractionLayer(nn.Module):
    """
    句法-语义融合交互层
    
    将SVO辅助任务的句法表示与BERT的语义表示进行门控融合，
    实现显式句法先验注入到GEC表示中。
    
    公式：
    - G = σ(W_g · [H_shared ; H_SVO] + b_g)
    - T = W_t · H_SVO + b_t
    - H_GEC_input = H_shared + G ⊙ T
    """
    def __init__(self, hidden_size: int):
        super().__init__()
        # 门控投影：2d -> d
        self.gate_proj = nn.Linear(hidden_size * 2, hidden_size)
        # 语法变换：d -> d
        self.syntax_transform = nn.Linear(hidden_size, hidden_size)
        # 可选：融合后的LayerNorm
        self.layer_norm = nn.LayerNorm(hidden_size)
    
    def forward(self, h_shared: torch.Tensor, h_svo: torch.Tensor) -> torch.Tensor:
        """
        Args:
            h_shared: [B, L, d] - BERT编码器输出
            h_svo: [B, L, d] - SVO中间表示
        Returns:
            h_gec_input: [B, L, d] - 融合后的表示
        """
        # 拼接
        concat = torch.cat([h_shared, h_svo], dim=-1)  # [B, L, 2d]
        # 门控向量
        gate = torch.sigmoid(self.gate_proj(concat))  # [B, L, d]
        # 语法变换
        syntax_transformed = self.syntax_transform(h_svo)  # [B, L, d]
        # 门控融合
        h_gec_input = h_shared + gate * syntax_transformed
        # LayerNorm
        h_gec_input = self.layer_norm(h_gec_input)
        return h_gec_input
```

#### 1.2 新增SVO中间表示生成层

**目的**：从BERT输出生成SVO任务的中间表示 `H_SVO`

```python
# 在GECModelWithMTL.__init__中新增
self.svo_hidden_proj = nn.Linear(config.hidden_size, config.hidden_size)
```

#### 1.3 新增模块三：错误感知多实例句级分类头

**替换原有的**：`self.sent_error_classifier = nn.Linear(config.hidden_size, 2)`

**新增类**：`ErrorAwareSentenceHead`

```python
class ErrorAwareSentenceHead(nn.Module):
    """
    错误感知多实例句级分类头
    
    将句子视为token实例集合，使用GEC预测的错误置信度驱动的
    注意力池化构造句级表示，显式对齐token-level与sentence-level。
    
    公式：
    - e_i = 1 - P(label_i = KEEP)  # 错误置信度
    - α_i = softmax(e_i)           # 错误驱动注意力
    - V_sent = Σ α_i · H_i         # 错误感知池化
    - y_sent = MLP(V_sent)         # 句级预测
    """
    def __init__(self, hidden_size: int, num_classes: int = 2):
        super().__init__()
        self.classifier = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size // 2, num_classes)
        )
    
    def forward(
        self, 
        h_tokens: torch.Tensor,      # [B, L, d]
        gec_logits: torch.Tensor,    # [B, L, C]
        attention_mask: torch.Tensor, # [B, L]
        keep_label_idx: int = 0       # KEEP标签的索引
    ) -> torch.Tensor:
        """
        Args:
            h_tokens: token级表示 (融合后的H_GEC_input)
            gec_logits: GEC Head的输出logits
            attention_mask: padding mask
            keep_label_idx: KEEP标签在标签表中的索引
        Returns:
            sent_logits: [B, num_classes]
        """
        # 1. 计算错误置信度 e = 1 - P(KEEP)
        gec_probs = torch.softmax(gec_logits, dim=-1)  # [B, L, C]
        p_keep = gec_probs[:, :, keep_label_idx]       # [B, L]
        error_confidence = 1 - p_keep                   # [B, L]
        
        # 2. Mask padding位置
        error_confidence = error_confidence.masked_fill(
            attention_mask == 0, float('-inf')
        )
        
        # 3. 错误驱动注意力权重
        alpha = torch.softmax(error_confidence, dim=-1)  # [B, L]
        
        # 4. 错误感知池化
        alpha = alpha.unsqueeze(-1)  # [B, L, 1]
        v_sent = torch.sum(alpha * h_tokens, dim=1)  # [B, d]
        
        # 5. 句级分类
        sent_logits = self.classifier(v_sent)  # [B, num_classes]
        
        return sent_logits
```

#### 1.4 修改 `GECModelWithMTL` 类

**修改__init__方法**：
```python
def __init__(self, config, num_gec_labels: int, num_svo_labels: int):
    super().__init__(config)
    self.num_gec_labels = num_gec_labels
    self.num_svo_labels = num_svo_labels
    
    # BERT Encoder
    self.bert = BertModel(config)
    
    # Dropout
    self.dropout = nn.Dropout(config.hidden_dropout_prob)
    
    # ========== 新增：SVO中间表示生成层 ==========
    self.svo_hidden_proj = nn.Linear(config.hidden_size, config.hidden_size)
    
    # ========== 新增：句法-语义融合交互层 ==========
    self.syntax_semantic_interaction = SyntaxSemanticInteractionLayer(config.hidden_size)
    
    # GEC Head (主任务) - 使用融合后的表示
    self.gec_classifier = nn.Linear(config.hidden_size, num_gec_labels)
    
    # SVO Head (辅助任务1) - 使用BERT输出
    self.svo_classifier = nn.Linear(config.hidden_size, num_svo_labels)
    
    # ========== 修改：错误感知句级分类头 ==========
    # 原: self.sent_error_classifier = nn.Linear(config.hidden_size, 2)
    self.sent_error_head = ErrorAwareSentenceHead(config.hidden_size, num_classes=2)
    
    self.init_weights()
```

**修改forward方法**：
```python
def forward(
    self,
    input_ids: torch.Tensor,
    attention_mask: Optional[torch.Tensor] = None,
    token_type_ids: Optional[torch.Tensor] = None,
    gec_labels: Optional[torch.Tensor] = None,
    svo_labels: Optional[torch.Tensor] = None,
    sent_labels: Optional[torch.Tensor] = None,
    label_mask: Optional[torch.Tensor] = None,
) -> Tuple[torch.Tensor, ...]:
    
    # BERT编码
    outputs = self.bert(
        input_ids=input_ids,
        attention_mask=attention_mask,
        token_type_ids=token_type_ids
    )
    
    # 获取序列输出 [batch_size, seq_len, hidden_size]
    h_shared = outputs.last_hidden_state
    h_shared = self.dropout(h_shared)
    
    # ========== 新增：生成SVO中间表示 ==========
    h_svo = self.svo_hidden_proj(h_shared)
    h_svo = torch.relu(h_svo)
    
    # ========== 新增：句法-语义融合 ==========
    h_gec_input = self.syntax_semantic_interaction(h_shared, h_svo)
    
    # SVO Head (使用h_shared)
    svo_logits = self.svo_classifier(h_shared)  # [B, L, num_svo_labels]
    
    # GEC Head (使用融合后的h_gec_input)
    gec_logits = self.gec_classifier(h_gec_input)  # [B, L, num_gec_labels]
    
    # ========== 修改：错误感知句级分类头 ==========
    sent_logits = self.sent_error_head(
        h_tokens=h_gec_input,
        gec_logits=gec_logits,
        attention_mask=attention_mask,
        keep_label_idx=0  # 假设KEEP是第0个标签
    )  # [B, 2]
    
    return gec_logits, svo_logits, sent_logits
```

---

### 2. `src/loss.py` - 损失函数修改

#### 2.1 新增模块二：不确定性加权损失

**新增类**：`UncertaintyWeightedLoss`

```python
class UncertaintyWeightedLoss(nn.Module):
    """
    基于同方差不确定性的动态多任务损失加权
    
    基于 "Multi-Task Learning Using Uncertainty to Weigh Losses" (CVPR 2018)
    
    公式：
    L_total = 1/2·exp(-s₁)·L_GEC + 1/2·exp(-s₂)·L_SVO + 1/2·exp(-s₃)·L_Sent
              + 1/2·(s₁ + s₂ + s₃)
    
    其中 s_i = log(σ_i²) 为可学习的对数方差参数
    """
    def __init__(self):
        super().__init__()
        # 初始化对数方差参数（log_vars = log(σ²)），初始为0
        self.log_var_gec = nn.Parameter(torch.zeros(1))
        self.log_var_svo = nn.Parameter(torch.zeros(1))
        self.log_var_sent = nn.Parameter(torch.zeros(1))
    
    def forward(
        self, 
        loss_gec: torch.Tensor, 
        loss_svo: torch.Tensor, 
        loss_sent: torch.Tensor
    ) -> Tuple[torch.Tensor, dict]:
        """
        Args:
            loss_gec: GEC任务损失
            loss_svo: SVO任务损失
            loss_sent: 句级任务损失
        Returns:
            total_loss: 加权后的总损失
            loss_dict: 包含各项损失和不确定性参数的字典
        """
        # 计算加权损失
        precision_gec = torch.exp(-self.log_var_gec)
        precision_svo = torch.exp(-self.log_var_svo)
        precision_sent = torch.exp(-self.log_var_sent)
        
        weighted_gec = 0.5 * precision_gec * loss_gec
        weighted_svo = 0.5 * precision_svo * loss_svo
        weighted_sent = 0.5 * precision_sent * loss_sent
        
        # 正则项
        regularization = 0.5 * (self.log_var_gec + self.log_var_svo + self.log_var_sent)
        
        # 总损失
        total_loss = weighted_gec + weighted_svo + weighted_sent + regularization
        
        # 返回详细信息用于日志记录
        loss_dict = {
            'loss_total': total_loss.item(),
            'loss_gec': loss_gec.item(),
            'loss_svo': loss_svo.item(),
            'loss_sent': loss_sent.item(),
            'log_var_gec': self.log_var_gec.item(),
            'log_var_svo': self.log_var_svo.item(),
            'log_var_sent': self.log_var_sent.item(),
            'sigma_gec': torch.exp(0.5 * self.log_var_gec).item(),
            'sigma_svo': torch.exp(0.5 * self.log_var_svo).item(),
            'sigma_sent': torch.exp(0.5 * self.log_var_sent).item(),
        }
        
        return total_loss, loss_dict
```

---

### 3. `src/trainer.py` - 训练器修改

#### 3.1 集成不确定性加权损失

**修改点**：
1. 在训练器初始化时创建 `UncertaintyWeightedLoss` 实例
2. 修改训练循环，使用不确定性加权计算总损失
3. 添加不确定性参数到优化器
4. 记录不确定性参数的训练曲线

```python
# 在Trainer.__init__中新增
from src.loss import UncertaintyWeightedLoss
self.uncertainty_loss = UncertaintyWeightedLoss().to(device)

# 修改优化器，添加不确定性参数
self.optimizer = torch.optim.AdamW([
    {'params': self.model.parameters()},
    {'params': self.uncertainty_loss.parameters(), 'lr': 1e-3}  # 不确定性参数用较大学习率
], lr=self.config.learning_rate)
```

---

### 4. `src/config.py` - 配置修改

**新增配置项**：
```python
# 句法-语义融合层配置
use_syntax_semantic_fusion: bool = True

# 不确定性加权配置
use_uncertainty_weighting: bool = True

# 错误感知句级头配置
use_error_aware_sent_head: bool = True
keep_label_idx: int = 0  # KEEP标签索引

# 是否detach错误置信度梯度（用于消融实验）
detach_error_confidence: bool = False
```

---

## 实施步骤

### 步骤1：修改 modeling.py
- [x] 新增 `SyntaxSemanticInteractionLayer` 类
- [x] 新增 `ErrorAwareSentenceHead` 类
- [x] 修改 `GECModelWithMTL.__init__`
- [x] 修改 `GECModelWithMTL.forward`

### 步骤2：修改 loss.py
- [x] 新增 `UncertaintyWeightedLoss` 类
- [x] 新增 `MultiTaskLossWithUncertainty` 类

### 步骤3：修改 trainer.py
- [x] 集成不确定性加权损失
- [x] 修改优化器配置
- [x] 添加训练日志记录

### 步骤4：修改 config.py
- [x] 添加新模块的配置项

### 步骤5：测试与验证
- [ ] 单元测试：验证各模块前向传播
- [ ] 集成测试：验证完整训练流程
- [ ] 梯度检查：确保梯度正常流动

---

## 注意事项

1. **Padding处理**：在错误感知句级头中，务必用attention_mask遮住padding位置
2. **KEEP标签索引**：需要确认label_map.txt中KEEP标签的实际索引
3. **梯度流动**：默认不detach错误置信度，让句级loss能反向影响token表示
4. **数值稳定性**：不确定性参数使用log_var形式，避免σ为负或过小

---

## 论文贡献点对应

| 贡献点 | 对应模块 | 代码文件 |
|--------|----------|----------|
| 结构层面：句法引导的表示细化 | SyntaxSemanticInteractionLayer | modeling.py |
| 优化层面：自适应多任务平衡 | UncertaintyWeightedLoss | loss.py |
| 预测层面：错误感知句级分类 | ErrorAwareSentenceHead | modeling.py |
