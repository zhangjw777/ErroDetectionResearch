# 本项目用于训练政府公文文本错误的检测模型，而不是纠错。以MACBert为基础设计任务头。

模型由三部分组成：

- 编码层（Encoder）：使用 MacBERT-Base/MacBert-Large。
- 多任务预测层（Multi-Task Heads）：
  - 主任务头：序列标注（GECToR Tagging Head），预测编辑标签（Keep/Delete/Append/Replace）。
  - 辅助任务头1：全句错误检测（Sentence-level Detection），判断句子是否有错。
  - 辅助任务头2（升级）：核心句法成分识别（Core Component Recognition）。与其让模型学习每个字的词性，不如强迫其理解句子的“骨架”。该Head预测每个字是否属于句子的主语（Subject）、谓语（Predicate）或宾语（Object）。这将赋予模型极强的结构感知能力，从而敏锐地捕捉“主语缺失”或“谓语残缺”等结构性病句 。
- 损失函数层：采用加权 Focal Loss 替代传统的 Cross Entropy。



### 核心改进一：序列标注体系的领域化定制

 

原生GECToR包含大量针对英文的标签（如动词时态变换、单复数变换）。对于中文公文，我们需要重新设计标签体系 ：

●   KEEP：保持不变（占比90%+）。

●   DELETE：删除该字（用于解决“成分赘余”）。

●   APPEND_{char}：在该字后插入字符（用于解决“成分缺失”）。由于常用汉字多达几千个，为了轻量化，我们仅保留公文高频虚词（如“的”、“和”、“是”）作为特定插入标签，其余情况预测通用APPEND_MASK，交由后处理模块填补。

●   REPLACE_{char}：替换为指定字符（用于解决“用词不当”）。同样采用高频混淆集策略。

 

### 核心改进二：引入Focal Loss 优化召回率

 

在检错任务中，正样本（错误字）与负样本（正确字）的比例极其悬殊（往往达到1:50甚至更低）。传统的交叉熵损失（Cross Entropy, CE）会使模型倾向于预测KEEP以获得较低的平均Loss，导致召回率极低。

本研究引入**Focal Loss** 进行改进。Focal Loss通过修改损失权重，使模型“关注”那些难以分类的样本（即错误样本）。

$$FL(p_t) = -\alpha_t (1 - p_t)^\gamma \log(p_t)$$

●   **$p_t$**：模型对正确类别的预测概率。

●   **$\gamma$**（聚焦参数）：建议设为2.0。当一个字是错误字但模型预测其为KEEP的概率很高时（$p_t$很小），$(1-p_t)^\gamma$项会变得很大，从而放大该样本的Loss，强迫模型去学习这个错误。

●   **$\alpha_t$**（平衡参数）：针对KEEP类设为0.25，针对错误类设为0.75，显式增加错误类的权重。

**理论意义**：通过调整$\gamma$和$\alpha$，我们可以灵活控制模型的“敏感度”。在公文检错场景下，适当调大$\alpha$可以显著提升召回率，虽然会牺牲少量精确率，但符合业务需求。

 

### 核心改进三：多任务学习（Multi-Task Learning, MTL）结构

 

为了解决公文中最棘手的“成分残缺”问题 ，我们在 MacBERT 的顶层引入了**句法结构监督信号**。

1. 任务定义的变化

原有的词性标注（POS）只能提供浅层的语法信息（例如知道“会议”是名词），但无法区分它是“主语”还是“宾语”。本研究将辅助任务升级为核心成分序列标注：

- **目标**：预测输入序列中每个 Token 的句法角色。
- **标签体系**：采用 **BIO** **标注模式** 设计简化的句法标签：
  - B-SUB,      I-SUB：主语成分（Subject）
  - B-PRED,      I-PRED：谓语/核心动词成分（Predicate）
  - B-OBJ,      I-OBJ：宾语成分（Object）
  - O：其他成分（定状补及虚词）
  - *注：对于公文检错，我们只关注主谓宾**“**骨架**”**的完整性，忽略细粒度的定状补标签以降低任务难度。*
- 网络结构修改

在训练阶段，模型的总损失函数由三部分构成：

$$L_{total} = L_{GEC} + \lambda_1 L_{SVO} + \lambda_2 L_{Sent}$$

- $L_{GEC}$：主任务的检错损失。
- $L_{SVO}$：核心成分识别的损失。通过该任务，模型被强制要求去“寻找”句子的主语和谓语。**如果一个句子在** **$L_{SVO}$** **任务中无法预测出** **B-SUB** **标签，但在** **$L_{GEC}$** **任务中却预测为** **KEEP**（无错），这种“认知冲突”会产生巨大的梯度，迫使编码层去重新审视句子的完整性。
- $\lambda_1,     \lambda_2$：超参数，建议 $\lambda_1$ 设为 0.5，给予句法结构中等强度的监督。



### 基于规则的错误生成（Rule-based Error Generation）



公文领域的标注数据稀缺是最大的研究障碍。必须采用数据增强（Data Augmentation）技术。利用公文的语言学特征反向生成错误数据 。

1. **混淆集替换**：建立公文常用词的音近/形近混淆集（如“权力”vs“权利”，“法治”vs“法制”）。随机替换正确语料中的词。
2. **介词掩码（Preposition Masking）**：针对“成分缺失”，编写规则随机删除句首的介词（如“通过”、“根据”）或句中的助词（“的”、“地”），模拟真实错误。

### 深度生成模型（CNEG与EdaCSC）

引入更高级的增强方法以提升数据的多样性。

- **CNEG****（Conditional Non-Autoregressive Error Generation）** 28：训练一个非自回归模型，输入正确句子，输出带有错误的句子。该方法能生成更自然的、符合人类犯错逻辑的样本。

- **EdaCSC策略**：

  - **Split Sentences**：将长公文切分为短句进行训练，防止模型对长下文产生依赖，增强局部检错能力。

  - **Reduce Typos**：在训练集中保留一定比例的“多错句”，防止模型学会“一句只改一处”的捷径。